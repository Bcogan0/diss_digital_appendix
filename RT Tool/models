# models.R
########################################
### Reaction Time Analysis
### Script for the contents of the ShinyApp Tool
### For the UI and Server see shiny_tool_v3.R
### Data: Simulator experiments in TU Berlin
### Supplement to:
### Dissertation Baris Cogan
###
### Authors: 
### Baris Cogan(baris.cogan@tu-berlin.de)
###
###  
########################################
# --- data loading and model fitting here ---
#Packages
#-----
library(tidyverse)
library(ggpubr)
library(rstatix)
library(dplyr)
library(reshape2)  # for melt() function
library(ggplot2)
library(readxl)
library(writexl)
library(report)
library(jtools)
library(Rcpp)
library(interactions)
library(MASS) #robust regression
library(fitdistrplus)
library(GeneralizedHyperbolic)
library(statmod)
library(glue)
library(rlang)
library(brms)
library(bayesQR)
library(usethis)
library(devtools)
library(effects)
library(performance) 
library(lme4)
library(rsq)
#library(MuMIn)
library(car)
library(rsq)
library(gridExtra)
library(cowplot)
library(psych) 
library(multcomp)
library(performance)
library(emmeans)
library(rstan)
library(caret)   # For cross-validation
library(boot)
library(sjPlot)
library(sm)
library(lmerTest)
library(MuMIn)
#survival
library(survminer)
library(survival)
library(bdsmatrix)
library(coxme)
library(JM)
library(flexsurv)
library(frailtypack)
#others
library(caret)
library(ggeffects)
library(shiny)
library(broom.mixed)
library(plotly)
library(renv)
library(latticeExtra)
library(see)
library(patchwork)
library(goftest)
library(fitdistrplus)
library(SurvRegCensCov)
library(glmnet)  # For ridge regression
library(pracma)     # for numerical integration (trapz)
library(Matrix)
library(robustlmm)
library(Metrics)  # for RMSE calculation
library(merTools) #CI
library(DHARMa) #regression diagnosis
#DATASET PREP
#upload and process rawdata
#------------
#rawdata
bbi <- read_excel("C:/Users/baris/OneDrive/Dokumente/Rprojects/sense/diss/data/bbi_data_filtered.xlsx") #speed outliers filtered, n=278
other_iv <- read_excel("C:/Users/baris/OneDrive/Dokumente/Rprojects/sense/diss/data/bbi_data_all.xlsx") #dataset with age, exp., n=287
survey<-read_excel("C:/Users/baris/OneDrive/Dokumente/Rprojects/sense/diss/data/surveys.xlsx") #Surveys KSS, NASA, PVT
##Duplicate the dataset for the analysis
bbi_all <- bbi
#Format the variables  as categorical/numeric
bbi_all$size_class <- as.factor(bbi_all$size_class)
bbi_all$contrast_class <- as.factor(bbi_all$contrast_class)
bbi_all$zbs <- as.factor(bbi_all$zbs)
bbi_all$angular_size<-as.factor(bbi_all$angular_size_arcmin)
bbi_all$angular_size_arcmin <- as.numeric(as.character(bbi_all$angular_size_arcmin))
bbi_all$subject <- as.factor(bbi_all$subject)
#Log transformation
bbi_all$rt_log<- log(bbi_all$rt)
##Set factor levels for dummy coding (bbi_all)
bbi_all$size_class <- factor(bbi$size_class, levels = c("180 cm", "90 cm")) # Change the reference level for size_class
bbi_all$contrast_class <- factor(bbi$contrast_class, levels = c("high", "low")) #Change the reference level for contrast_class
bbi_all$zbs <- factor(bbi$zbs, levels = c("pzb", "fas", "etcs")) # Change the reference level for zbs
bbi_all$speed_class <- factor(bbi$speed_class, levels = c("100 km/h", "40 km/h", "160 km/h")) # Change the reference level for speed_class
#Edit the factor levels with dummy coding
bbi_all_tool<-bbi_all
# Replace "fas" with "os" in the 'zbs' column
bbi_all_tool$zbs <- gsub("fas", "os", bbi_all_tool$zbs)
bbi_all_tool$zbs <- factor(bbi_all_tool$zbs, levels = c("pzb", "os", "etcs"))
#-------------------------------------------------------
# Fit the models
lmer_standard_tool <- lmer(rt_log ~ angular_size_arcmin + contrast_class + speed + zbs + (1 | subject), data = bbi_all_tool)
bbi_all_tool$event <- 1
surv_obj_tool <- with(bbi_all_tool, Surv(time = rt, event = event))
aftflex_tool <- flexsurvreg(surv_obj_tool ~ size_class + contrast_class + speed_class + zbs, data = bbi_all_tool, dist = "weibull")

# Function to predict reaction time given new data.
predict_reaction_time <- function(newdata) {
  predicted_log_rt <- predict(lmer_standard_tool, newdata = newdata, re.form = NA)
  exp(predicted_log_rt)
}

predict_CI <- function(newdata) {
  newdata$subject <- NA
  newdata$subject <- factor(levels(bbi_all_tool$subject)[1], levels = levels(bbi_all_tool$subject))
  pred_interval <- predictInterval(lmer_standard_tool, 
                                   newdata = newdata,
                                   level = 0.95, 
                                   n.sims = 1000, 
                                   which = "fixed")
  pred_interval
  
  }

# Define the percentiles vector for quantile prediction
pct2 <- 0:100/100
survival <- 1 - pct2

# New survival prediction function with updated logic:
predict_survival_rate <- function(newdata, t) {
  # Check special condition: if zbs equals "fas" and speed_class is "100 km/h" or "160 km/h", return NA.
  if(newdata$zbs == "fas" && (newdata$speed_class %in% c("100 km/h", "160 km/h"))) {
    st <- NA
    predict_comb <- rep(NA, length(pct2))
  } else {
    # Predict survival probability at time t.
    st_obj <- predict(aftflex_tool, newdata = newdata, type = "survival", times = t)
    st <- st_obj$.pred_survival
    # Predict quantiles over pct2.
    predict_comb <- predict(aftflex_tool, newdata = newdata, type = "quantile", p = pct2)
    # Extract the quantile predictions.
    predict_comb <- predict_comb[[1]][[1]]
    predict_comb <- predict_comb$.pred_quantile

  }
  return(list(st = st, predict_comb = predict_comb))
}

